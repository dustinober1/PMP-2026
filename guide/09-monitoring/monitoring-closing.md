# 9.1 Monitoring & Controlling (Control & Change)

Monitoring is about **observing** performance; controlling is about **taking action** when performance deviates from the plan. In the 2026 PMP exam, this is where you prove you can run a project with discipline: detect problems early, diagnose the cause, act appropriately, and communicate transparently.

::: tip ğŸ¯ What the Exam Tests
Most Monitoring & Controlling questions are scenario-based and ask **â€œWhat should the PM do FIRST?â€** A safe pattern is:
1) confirm the variance is real (data) â†’ 2) analyze impact/root cause â†’ 3) choose an action (corrective, preventive, defect repair) â†’ 4) submit a change request if baselines/contracts must change â†’ 5) implement approved changes and communicate.
:::

::: info ğŸ”§ Templates (Copy/Paste)
Need a status report, change request form, variance log, or closure checklist? Use [9.3 Tools & Templates](./toolkit).
:::

::: info ğŸ§­ The Control Loop (Mental Model)
```
Work happens â†’ Collect WPD â†’ Analyze (WPI) â†’ Decide â†’ Act â†’ Communicate (WPR) â†’ Repeat

If the decision changes a baseline or contract:
Change Request â†’ Integrated Change Control â†’ Approved Change â†’ Implement â†’ Re-baseline
```
:::

---

## Monitoring & Controlling Processes (PMBOK-Aligned)

These are the most testable â€œcontrolâ€ processes. You donâ€™t need to memorize them as a list, but you should know what each one *does* and what it typically outputs.

| Process | Knowledge Area | Exam framing (why it exists) |
|---|---|---|
| **Monitor and Control Project Work** | Integration | Detect variance, recommend actions, create work performance reports |
| **Perform Integrated Change Control** | Integration | Evaluate/approve/reject changes and protect baselines |
| **Validate Scope** | Scope | Get formal acceptance of completed deliverables |
| **Control Scope** | Scope | Prevent scope creep; manage changes to requirements/WBS/backlog |
| **Control Schedule** | Schedule | Keep delivery dates realistic; manage critical path impacts |
| **Control Costs** | Cost | Forecast EAC; keep funding aligned to actual performance |
| **Control Quality** | Quality | Inspect/testing; confirm deliverables meet requirements |
| **Control Resources** | Resource | Resolve resource conflicts; ensure resources are available and used effectively |
| **Monitor Communications** | Communications | Ensure the right people get the right info at the right time |
| **Monitor Risks** | Risk | Track triggers, residual/new risks; verify risk responses worked |
| **Control Procurements** | Procurement | Manage vendor performance, claims, payments, contract changes |
| **Monitor Stakeholder Engagement** | Stakeholder | Measure engagement effectiveness; adjust strategy |

---

## Work Performance Data â†’ Information â†’ Reports (The â€œControl Funnelâ€)

This transformation is how you turn â€œnoiseâ€ into decisions.

| Level | What it is | Examples | Primary audience |
|---|---|---|---|
| **Work Performance Data (WPD)** | Raw observations | hours spent, defect count, completed story points, % complete | team |
| **Work Performance Information (WPI)** | Analyzed status/variance/trends | CPI/SPI, burnup trend, defect escape rate, forecast date | PM/core team |
| **Work Performance Reports (WPR)** | Packaged communication | status reports, dashboards, steering decks | sponsor/stakeholders |

### ğŸ§  Concrete Example: The "Quality Spike"
1.  **Data (WPD):** The tester logs "5 defects found" in Jira today. (Raw number, no context).
2.  **Information (WPI):** The PM analyzes this and notes, "Defect rate has jumped 20% this week; we are now projected to miss the UAT start date by 3 days." (Context + Implication).
3.  **Report (WPR):** The Weekly Status Report to the Sponsor shows a "Yellow" quality status with a note: "Defect trend rising; conducting root cause analysis to protect UAT date." (Decision-ready).

::: warning âš ï¸ Common Exam Trap
Stakeholders being â€œsurprisedâ€ by bad news usually means you collected **data** but didnâ€™t transform it into **information** and communicate it via **reports**.
:::

---

## Baselines, Thresholds, and Reserves (How â€œControlâ€ Actually Works)

- **Baselines** are the approved versions of **scope, schedule, and cost** used for comparison (your â€œtruthâ€ for variance).
  - **Scope baseline**: scope statement + WBS + WBS dictionary (or an approved requirements baseline/backlog in adaptive).
  - **Schedule baseline**: the approved schedule model (logic, dates, milestones).
  - **Cost baseline**: the time-phased budget used to measure performance (often shown as an S-curve).
- **Thresholds** are â€œtrigger pointsâ€ (e.g., â€œ>10% schedule variance requires sponsor notificationâ€) defined in the PM plan.
  - Thresholds enable **management by exception**: you donâ€™t escalate every wobbleâ€”only variances beyond agreed limits.
- **Contingency reserve** is for *identified risks* (typically part of the cost baseline). When a known risk occurs, you execute the risk response and use contingency as planned.
- **Management reserve** is for *unknown-unknowns* (not in the baseline; typically requires sponsor approval to use and often triggers a change request).

::: warning âš ï¸ Common Exam Trap
â€œUsing a reserveâ€ is not the same as â€œchanging the baseline.â€
- If the plan already included **contingency** for a known risk, using it can be acceptable without re-baselining.
- If you need **more time/money/scope** than the baselines allow (or you need **management reserve**), you normally go through **change control**.
:::

---

## ğŸï¸ Earned Value Management (EVM)

EVM is an objective way to answer: **Are we getting the value we planned for the money and time weâ€™re spending?** Itâ€™s most common in predictive/hybrid projects with a defined baseline.

### EVM Inputs (Know These Cold)

| Term | Meaning | Typical calculation |
|---|---|---|
| **BAC** | Budget at Completion | total planned budget |
| **PV** | Planned Value | `% planned complete Ã— BAC` |
| **EV** | Earned Value | `% actually complete Ã— BAC` |
| **AC** | Actual Cost | total spent to date |

### Core Performance Measures (Most Tested)

| Metric | Formula | Good sign |
|---|---|---|
| **CV** (Cost Variance) | `EV - AC` | positive = under budget |
| **SV** (Schedule Variance) | `EV - PV` | positive = ahead of schedule |
| **CPI** (Cost Performance Index) | `EV / AC` | > 1.0 = under budget |
| **SPI** (Schedule Performance Index) | `EV / PV` | > 1.0 = ahead |

::: info ğŸ” CPI/SPI Combo Quick Read (Know the Story)
| CPI | SPI | What it usually means | Exam-appropriate move |
|---:|---:|---|---|
| `< 1` | `< 1` | over budget + behind schedule | analyze root cause, update forecast (EAC), propose recovery options; submit CR if baselines must change |
| `< 1` | `> 1` | over budget but ahead of schedule | confirm cost drivers (crashing/overtime/vendor rates); decide corrective action; CR if baseline needs change |
| `> 1` | `< 1` | under budget but behind schedule | validate schedule logic/critical path; remove constraints; CR if finish date must move |
| `> 1` | `> 1` | under budget + ahead of schedule | confirm data quality; communicate; consider pulling value forward (if governance allows) |
:::

::: tip ğŸ’¡ Schedule Nuance (Exam Clarity)
EVM **SV** and **SPI** indicate schedule performance in â€œplanned valueâ€ terms. If the question is about *calendar impact*, verify the **critical path/float** in the schedule model.
:::

### Forecasting (Shows Up in â€œWhat happens at the end?â€ Questions)

| Metric | What it answers | Formula (common) |
|---|---|---|
| **EAC** | â€œWhat will the total cost be?â€ | `BAC / CPI` (if current cost performance continues) |
| **EAC** (alt) | â€œIf future work follows planâ€¦â€ | `AC + (BAC - EV)` |
| **ETC** | â€œHow much more will we spend?â€ | `EAC - AC` |
| **VAC** | â€œHow far over/under budget at finish?â€ | `BAC - EAC` |
| **TCPI** | â€œHow efficient must we be from now on?â€ | `(BAC - EV) / (BAC - AC)` (to meet BAC) |
| **TCPI** (alt) | â€œâ€¦to meet the new EAC?â€ | `(BAC - EV) / (EAC - AC)` |

::: tip ğŸ’¡ 2026 Strategy: Trend > Snapshot
A single CPI/SPI is a snapshot. A **trend** (e.g., CPI has declined 4 reporting periods) is the early-warning signal. Treat trend breaks as â€œinvestigate now,â€ not â€œwait until itâ€™s bad.â€
:::

### Worked Example (So You Can Do It Under Time Pressure)

Assume:
- `BAC = $200,000`
- by this date you planned to be `50%` complete â†’ `PV = $100,000`
- you are actually `40%` complete â†’ `EV = $80,000`
- you spent `AC = $110,000`

Results:
- `CV = EV - AC = -$30,000` (over budget)
- `SV = EV - PV = -$20,000` (behind schedule)
- `CPI = EV/AC = 0.73` (cost efficiency is poor)
- `SPI = EV/PV = 0.80` (schedule efficiency is poor)
- `EAC = BAC/CPI â‰ˆ $273,973` (forecast: likely over budget if nothing changes)

**Exam-appropriate next move**: perform variance + root cause analysis, update forecasts, and communicate impact; submit a change request if you need additional budget/time or to change scope/quality expectations.

---

## Variance, Trend, and Root Cause Analysis (Donâ€™t Skip This Step)

When a variance appears, the PMâ€™s job is not to â€œfix it fast.â€ The PMâ€™s job is to **understand it** so the action actually works.

Common analysis tools (often appear as answer choices):
- **Variance analysis** (compare actual vs baseline).
- **Trend analysis** (is it getting better/worse over time?).
- **Root cause analysis**:
    - **5 Whys**: Ask "Why?" five times to drill down from the symptom to the fundamental cause.
    - **Fishbone (Ishikawa) diagram**: Visualizes cause-and-effect, breaking causes into categories (e.g., People, Process, Technology).
- **Pareto chart (80/20)**: A histogram ordered by frequency to highlight the â€œvital fewâ€ causes that generate most problems. Use this to prioritize *where* to fix things.

::: info ğŸ§ª Control Charts (Quality Control)
- **Control limits** (UCL/LCL) show whether a process is statistically stable.
- A process can be **in control but out of spec** (customer limits â‰  control limits).
- "Out of control" signals include points outside limits or non-random patterns (e.g., a sustained run on one side of the mean).
:::

#### ğŸ§  Quality Metrics During Monitoring

**Common Quality Metrics to Monitor:**

| Metric | What it measures | Why it matters | Action if bad |
|---|---|---|---|
| **Defect escape rate** | % defects that escape to production/UAT | quality signal; rework cost | RCA; improve review process |
| **Rework rate** | % effort spent fixing defects vs new work | productivity impact; schedule risk | identify root causes; adjust estimates |
| **Defect density** | defects per 1000 lines of code (KLOC) | code quality signal | compare to baseline; escalate if rising |
| **Test coverage %** | % of code/features tested | quality visibility | increase coverage for high-risk areas |
| **Mean time to resolution (MTTR)** | avg time from defect found to closed | development efficiency | identify blockers; staffing needs |
| **Phase containment rate** | % defects found/fixed in the phase they're created | process effectiveness | earlier phases should catch more |

**Control Chart Interpretation:**
- **Point outside control limits** â†’ Process is out of control (special-cause variation; investigate immediately)
- **Run of 7+ points on one side of mean** â†’ Process drifting; investigate
- **Trends or cycles** â†’ Systematic change; not random variation
- **Points within control limits** â†’ Process is stable (predictable)

**BUT: Stable doesn't mean capable.** A process can be in statistical control while consistently producing defects outside customer spec. You need both **stability** (control chart) and **capability** (Cpk, Pp metrics) for true quality.

#### ğŸ§  Defect Escape Scenario

**Scenario**:
- Phase 1 (Dev): 20 defects created
- Phase 1 testing: Find 15, escape 5 to Phase 2
- Phase 2 testing: Find 4, escape 1 to UAT
- UAT: Find 1 (total escaped = 1)

**Phase Containment Rate** (Phase 1): 15/20 = 75% (good target: 85%+)

**Defect Escape Rate** (Phase 1 â†’ later): 5/20 = 25% (escalating signal)

**Action**: If escape rate is rising trend (25% â†’ 35% â†’ 45%), escalate and implement preventive action (peer review process, definition of done clarity, automated testing).

---

## ğŸ—“ï¸ Control Schedule: Critical Path, Float, and Compression

Many exam questions hide the real issue in schedule logic. Before you â€œfix the date,â€ confirm whether the slip is actually threatening the end date.

- **Critical path**: the longest path through the network; activities on it typically have **zero total float**.
- **Float (slack)**: allowable delay without delaying the project end date (or the next dependent activity).
- **Total Float**: How much an activity can slip without delaying the project end date.
- **Free Float**: How much an activity can slip without delaying the next dependent activity (more restrictive for successor tasks).
- **If the slipped activity has float**: you may not need a baseline change; you may need replanning/resequencing and communication.
- **If the slipped activity is on the critical path**: you need a recovery decision (scope trade-off, schedule compression, or a baseline change via CR).

#### ğŸ§  Worked Example: Float & Critical Path Analysis

**Scenario**:
- Forward pass (ES â†’ EF): Activity A ends at day 10, Activity B (dependent) ends at day 15
- Backward pass (LS â†’ LF): Activity A must start by day 5 (LF = day 10 to meet day 15 deadline)
- Activity A: ES = 0, EF = 10, LS = 5, LF = 10 â†’ **Total Float = 5 days** (can slip from day 0 to day 5 start without impacting project end date)

**Applied to Monitoring**:
- If Activity A slips by 2 days, you still have 3 days of buffer â†’ no change request needed (just communicate)
- If Activity A slips by 6 days, you exceed the float â†’ cascade to Activity B and potentially the project end date â†’ **change request/baseline change likely**

**For Critical Path Activities** (Total Float = 0):
- Any slip = project delay
- Monitor relentlessly; even small variances require mitigation
- Use float trending as an early warning indicator

### Schedule Compression (Know the Two Levers)

| Technique | What it is | Trade-off / risk |
|---|---|---|
| **Crashing** | add resources/cost to shorten duration | increases cost; may increase coordination risk |
| **Fast tracking** | overlap activities previously sequential | increases rework/defect risk; adds uncertainty |

#### ğŸ§  Worked Example: Crashing vs Fast-Tracking

**Scenario**: A critical path activity is 10 days and is slipping. Original plan: $50K, 10 days. Sponsor cannot move deadline.

**Option A: Crash (Add Resources/Cost)**
- Add an extra developer for $30K
- Reduces duration from 10 â†’ 7 days
- Total cost impact: +$30K
- Rework risk: low (same people, parallel work on same task)
- Best when: cost is available and you want to minimize quality risk

**Option B: Fast-Track (Overlap Activities)**
- Start testing while development wraps up (normally sequential)
- Reduces total path by 3 days (dev 7 days + test 4 days in parallel vs 10 + 4 sequential)
- Cost impact: minimal (maybe +$10K for QA to prep early)
- Rework risk: high (defects found in parallel work must be reworked)
- Best when: cost is constrained and you can accept quality risk

**Decision on the Exam**: Crashing is preferred when money is available; fast-tracking is preferred when money is tight. Both require monitoring because they increase risk.

::: warning âš ï¸ Critical Path Dependency
Only compressing critical path activities reduces project duration. If a slipped activity has **float/slack**, you may not need compressionâ€”you may just need **replanning/resequencing**.
:::

::: tip ğŸ’¡ Exam Pattern
If the question says "What should the PM do FIRST?" the safest first step is usually: **analyze the variance + confirm critical path impact** before choosing crash/fast-track or requesting more time.
:::

---

## Issues vs Risks vs Change Requests (Stop Mixing These Up)

Exam questions often test whether you can choose the right "container" for the problem.

| Item | Time horizon | Where you track it | What you do next |
|---|---|---|---|
| **Issue** | happening now | **Issue log** | assign an owner + due date, remove blockers, escalate if needed |
| **Risk** | may happen later | **Risk register** | monitor triggers, reassess probability/impact, implement response plans |
| **Change request** | decision needed | **Change log / change control system** | analyze impacts, route to change authority/CCB, update baselines if approved |

Key relationship: a **risk becomes an issue** when it occurs; issues and variances often **generate change requests** when the baseline must be updated.

#### ğŸ§  Decision Tree: Where Do I Log This?

```
Is the problem HAPPENING RIGHT NOW?
â”œâ”€ YES â†’ ISSUE LOG
â”‚  â””â”€ Example: Test environment is down today
â”‚  â””â”€ Example: Key developer called in sick
â”‚  â””â”€ Example: UAT data is corrupted
â”‚
â””â”€ NO, it MIGHT happen later â†’ Continueâ€¦
   â””â”€ Is it a known risk we identified in the Risk Register?
      â”œâ”€ YES â†’ Monitor RISK REGISTER (check triggers, execute response)
      â”‚  â””â”€ Example: Vendor delays > 6 weeks
      â”‚  â””â”€ Example: Technical integration risk with legacy system
      â”‚
      â””â”€ NO, it's a NEW risk â†’ Add to RISK REGISTER
         â””â”€ Example: New regulatory requirement discovered
         â””â”€ Example: Team attrition risk (wasn't planned for)

AFTER you address the issue/risk, does it require changing scope/schedule/cost/contracts?
â”œâ”€ YES â†’ Submit CHANGE REQUEST
â”‚  â””â”€ If approved: update baselines (scope/schedule/cost)
â”‚  â””â”€ If rejected/deferred: log decision and communicate
â”‚
â””â”€ NO â†’ Close issue/update risk register and communicate
```

#### ğŸ§¯ Real-World Scenarios

**Scenario 1**: "UAT failed because acceptance criteria were missing"
- Current status: UAT is blocked RIGHT NOW
- Log: **Issue log** (and escalate to get criteria defined)
- Follow-up: May become a **change request** if rework changes schedule/cost
- May prevent in future: Add **preventive action** (always document acceptance criteria before dev starts)

**Scenario 2**: "Vendor might delay shipment if lead times extend beyond 6 weeks"
- Current status: Not happening yet; we identified this risk
- Log: **Risk register** (with trigger, response plan, owner)
- Monitor: Watch for the trigger (supplier ETA becomes 6+ weeks)
- If triggered: Execute response (e.g., pre-order, find alternate supplier) and possibly log an **issue** or **change request**

**Scenario 3**: "Customer suddenly wants dark mode added"
- Current status: Request just came in (happening now)
- Log: **Change request** (not an issue, not a risk; it's a change decision)
- Process: Analyze impacts â†’ route to CCB/product governance â†’ decide approve/reject/defer
- If approved: Update backlog/schedule baseline

### ğŸ§¯ Risk Monitoring Essentials (Triggers, Residual, Secondary)

- **Triggers**: warning signs that a risk is about to occur (your cue to implement the planned response).
- **Residual risk**: what remains after response actions (still needs monitoring).
- **Secondary risk**: new risks created by your response (e.g., fast-tracking creates rework risk).
- **Risk reassessment**: periodic review to update probability/impact and identify new risks.
- **Risk audit**: verify whether risk responses were implemented and whether they worked.

If a risk occurs (becomes an issue), execute the response plan, update the **risk register** and **issue log**, and submit a **change request** if the response changes baselines/contracts.

---

## Corrective Action vs Preventive Action vs Defect Repair

These terms show up constantly in Monitoring & Controlling questions.

| Term | Purpose | Example |
|---|---|---|
| **Corrective action** | Bring future performance back to plan | add a tester to stop defect backlog growth |
| **Preventive action** | Reduce probability of future negative variance | add peer reviews to prevent defects |
| **Defect repair** | Fix a nonconforming deliverable | patch a production bug found in UAT |

**Important nuance**: If the action changes an approved baseline (scope/schedule/cost) or contract terms, you typically need a **change request**.

---

## ğŸ—ï¸ Integrated Change Control (How to Change Without Chaos)

Changes are normal. **Uncontrolled** changes are project killers.

### Key Definitions
- A **change request** can be for a scope change, schedule/budget change, corrective action, preventive action, defect repair, or updates to plans/documents.
- The **CCB** (Change Control Board) is the *decision authority* in many predictive environments. In agile/hybrid, approval is often handled through **product ownership/governance** and **backlog prioritization** (but itâ€™s still a decision process).

<div class="change-process">
  <div class="process-step">
    <div class="step-num">1</div>
    <div class="step-title">Capture</div>
    <p>Document the request (donâ€™t accept hallway changes). Update the change log.</p>
  </div>
  <div class="process-step">
    <div class="step-num">2</div>
    <div class="step-title">Analyze</div>
    <p>Assess impact to <strong>scope, schedule, cost, quality, risk, and benefits</strong>. Include options.</p>
  </div>
  <div class="process-step">
    <div class="step-num">3</div>
    <div class="step-title">Decide</div>
    <p>CCB/sponsor/product governance approves, rejects, or defers. Define funding and timeline impacts.</p>
  </div>
  <div class="process-step">
    <div class="step-num">4</div>
    <div class="step-title">Implement</div>
    <p>Execute the approved change via project work. Update baselines/plans and communicate to stakeholders.</p>
  </div>
</div>

### What Gets Updated After an Approved Change (Outputs You Should â€œSeeâ€)

When a change is approved, you typically update:
- **Change log** (status + decision) and often a **decision log**
- **Project management plan** (including **scope/schedule/cost baselines** if impacted)
- **Project documents** (requirements/backlog, schedule model, risk register, issue log, communications plan, forecasts)
- **Work**: implement the approved change and communicate the new expectations

On the exam, â€œimplement the changeâ€ is rarely correct until you also see **approval**, **baseline/document updates**, and **communication**.

::: warning âš ï¸ Another Common Exam Trap
If stakeholders ask for â€œa small change,â€ you donâ€™t do it â€œto be nice.â€ You route it through the **change control process**. â€œDeath by a thousand cutsâ€ is still scope creep.
:::

---

## Controlling More Than Schedule and Cost (Exam Bread-and-Butter)

Monitoring & Controlling touches every knowledge area. Think in terms of *what you measure* and *what you do when itâ€™s off*.

| Area | What you monitor | Common controls/actions |
|---|---|---|
| **Scope** | acceptance criteria, requirement completion | validate scope (acceptance), prevent scope creep, change requests |
| **Schedule** | critical path, milestones, trend vs baseline | re-sequence work, remove blockers, crash/fast-track (with risk review) |
| **Cost** | burn rate, CPI, EAC, reserves | re-forecast, manage reserves, request funding changes |
| **Quality** | defects, rework rate, control charts | inspections/testing, defect repair, process adjustments |
| **Risk** | triggers, residual/new risks | risk reassessment, audits, execute fallback/contingency |
| **Procurement** | vendor performance, deliverable acceptance | performance reviews, claims management, contract change control |
| **Stakeholders/Comms** | sentiment, feedback loops, understanding | adjust comms strategy, tailor reporting, address concerns early |

---

## ğŸ“Š Agile & Hybrid Visibility

In adaptive environments, control focuses on **value flow and predictability**, not variance from a fixed scope baseline.

- **Burnup/Burndown**:
    - **Burndown**: Tracks work remaining. A "flat line" means work is stalled. A spike up means scope was added.
    - **Burnup**: Tracks work completed vs. total scope. Better for visibility when scope is changing (you see the target line move).
- **Velocity**: How much work the team gets "Done" per iteration. Use it to forecast *future* capacity, not as a performance target to be forced.
- **Cycle Time vs. Lead Time**:
    - **Lead Time**: Clock starts when the customer requests it (ticket created) â†’ ends when value is delivered (deployment).
    - **Cycle Time**: Clock starts when the team begins work (In Progress) â†’ ends when work is Done.
- **Cumulative Flow Diagram (CFD)**: Visualizes flow stability. Widening bands indicate bottlenecks. Vertical steps mean batch transfers (bad flow).
- **WIP Limits**: Constraints placed on columns (e.g., "Doing") to force teams to finish starting before starting new work.
- **Escaped defects**: quality signal (defects found after â€œdoneâ€).

::: tip ğŸ’¡ Agile Change Control
In agile, change is expected. â€œControlâ€ is achieved by maintaining a transparent, ordered backlog, stable iteration cadence, clear acceptance criteria, and regular inspect/adapt events (review + retro).
:::

<style>
.change-process {
  display: flex;
  flex-direction: column;
  gap: 1rem;
  margin: 2rem 0;
}

.process-step {
  display: flex;
  align-items: flex-start;
  gap: 1.5rem;
  padding: 1rem;
  background: var(--vp-c-bg-mute);
  border-radius: 8px;
}

.step-num {
  background: var(--vp-c-brand);
  color: white;
  width: 32px;
  height: 32px;
  border-radius: 50%;
  display: flex;
  align-items: center;
  justify-content: center;
  font-weight: 800;
  flex-shrink: 0;
}

.step-title {
  font-weight: 700;
  margin-bottom: 0.25rem;
}

.process-step p {
  margin: 0;
  font-size: 0.9rem;
  color: var(--vp-c-text-2);
}
</style>

---

<div class="study-tip">
  <strong>ğŸ“ Exam Insight:</strong> â€œGold platingâ€ (adding extras the customer didnâ€™t ask for) is not a kindnessâ€”it's an uncontrolled scope change that increases risk and can violate contract terms. Deliver what was agreed, then submit enhancements as formal change requests.
</div>

<style>
.study-tip {
  background: var(--vp-c-brand-soft);
  border-left: 4px solid var(--vp-c-brand);
  padding: 1rem;
  border-radius: 8px;
  margin: 2rem 0;
}
</style>
