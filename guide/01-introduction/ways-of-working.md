---
title: 1.3 – Ways of Working and Tailoring for Context
description: 1.3 – Ways of Working and Tailoring for Context
---

# 1.3 – Ways of Working and Tailoring for Context

The modern PMP is expected to be fluent in multiple ways of working: predictive, agile, and hybrid. The exam does not reward loyalty to one methodology; it rewards your ability to choose and tailor the approach that best delivers value in a given context.

By the end of this chapter, you should be able to:

- Describe predictive, agile, and hybrid ways of working in practical terms
- Explain when each approach tends to work well (and when it does not)
- Understand how governance, planning, and change control differ across approaches
- Apply tailoring principles to adapt your way of working to specific project contexts
- Recognize exam questions that test your ability to choose and justify an appropriate approach

Use this section as your mental "toolbelt" for ways of working. While other parts of this book focus on *what* to deliver (value, scope), this section is about choosing *how* you will organize the work so that value can actually be delivered.

---

## Opening Story: The New Project Manager's First Month

Meet Sarah, a newly promoted project manager at a mid-size organization. In her first month, she is assigned three very different initiatives:

1. A renovation of the corporate office building
2. A redesign of the company's internal expense reporting software
3. A strategic transformation project combining both the office redesign and new processes for how teams work together

On her first day, Sarah thinks: *"I learned the PMBOK; I know how to manage projects. I'll use the same approach for all three."*

By the end of her first month, Sarah realizes her mistake. Each project needed a different way of working, and she almost derailed one project by using the wrong approach. This chapter walks through Sarah's learning journey and explores why the approach that works beautifully for one project can actually hinder another.

By the end of this chapter, you will understand not only *what* the three approaches are, but *why* Sarah needed to think differently about each project, and how to make similar choices on the exam.

---

## 1.3.1 What PMI Means by “Ways of Working”

PMI uses the phrase “ways of working” to emphasize that:

- There is no single “correct” method for all projects.  
- You are expected to know multiple approaches and use them appropriately.  
- You should tailor your approach based on context, not personal preference.

The three high-level categories you will see throughout the Exam Content Outline are:

- Predictive (sometimes called “waterfall”)  
- Agile / adaptive  
- Hybrid (a context-appropriate mix of both)

Key idea:

- Predictive approaches assume that requirements can be understood reasonably well upfront, and that change is relatively controlled.
- Agile/adaptive approaches assume high uncertainty and change, and explicitly use iteration, feedback, and incremental delivery to manage that.
- Hybrid approaches recognize that most real initiatives have elements that are more stable and elements that are more uncertain and combine practices accordingly.

**Understanding context complexity**: Choosing the right approach requires understanding whether your project operates in simple, complicated, or complex environments. For a deep dive into complexity theory and the Cynefin Framework, see **Section 7.2 – Navigating Complexity in Projects**, which provides tools for diagnosing context and adapting your approach accordingly.

On the exam, you will rarely be asked to recite definitions. Instead, you will be placed in scenarios and expected to:

- Recognize which way of working is being used (or should be used).  
- Make decisions consistent with that approach while still protecting value, benefits, and stakeholder needs.

---

## 1.3.2 Predictive Approaches in Practice

Predictive approaches are structured, plan-driven methods where:

- Scope is defined in detail early in the project
- A baseline schedule and budget are established
- Changes are managed through formal change control
- Success is measured against those baselines

The fundamental assumption: *You can predict most of what will happen because the path is well-understood.*

Examples of predictive environments:

- Construction and infrastructure projects
- Highly regulated industries (pharmaceutical manufacturing, nuclear, aviation)
- Large procurements with fixed-price contracts and detailed specifications
- Complex systems integration where the pieces must fit together precisely

### 1.3.2.1 Story: Sarah's Office Renovation (Sarah's First Project)

Sarah's first assignment is to manage the renovation of the corporate office building. The company is moving to a new location in 18 months. Here is what happens:

**Week 1: The Planning Phase**

Sarah meets with the facilities team, the CFO, and department heads. They define the scope carefully:

- Exact square footage needed
- Layout based on the company's current and projected headcount
- Which departments sit where
- Technology infrastructure (network drops, power, meeting room setups)
- Aesthetic requirements and brand standards
- Regulatory requirements (accessibility, safety codes, fire ratings)

All of this is documented in a 60-page scope statement and detailed floor plans. Contractors review these plans and bid on the project with fixed prices. The project has:

- A fixed budget: $4.2 million
- A firm deadline: 18 months
- Non-negotiable regulatory compliance
- Safety and structural requirements that do not change based on mood or market whims

**Week 4: The Schedule Emerges**

Sarah works with the general contractor to build a critical path schedule:

- Foundation and structural work (Months 1–4)
- MEP systems—mechanical, electrical, plumbing (Months 3–8)
- Interior walls and doors (Months 5–10)
- Flooring, paint, and finishes (Months 9–14)
- Furniture installation and move-in (Months 15–18)

The contractor explains: *"Some tasks have slack; others are on the critical path. If we slip the foundation by two weeks, the entire project slips two weeks unless we accelerate later work at significant cost."*

Sarah now understands: In this environment, detailed upfront planning is not bureaucratic overhead—it is essential risk management.

**Week 12: Change Request Arrives**

The VP of Engineering walks into Sarah's office: *"We didn't know how many servers we'd need. Can we add three large server rooms instead of two?"*

This seems reasonable, but adding space requires:

- Redesigning the floor plan
- Rerouting MEP systems (already being built)
- Changing foundation work (already underway)
- Potential asbestos testing in the modified spaces (regulatory requirement)
- Estimated cost impact: $250,000
- Schedule impact: 4 weeks

Sarah presents this to the Change Control Board, which includes the VP of Finance, the CIO, and the VP of Engineering. She shows:

- The change request and justification
- Impact analysis on cost, schedule, risk, and scope
- Alternatives (could they use the cloud instead? Can they prioritize what goes where?)
- The implications for the move date

The board makes an informed decision: Either pay the $250,000 and slip the timeline, or find an alternative to manage server needs. They choose to accept both the cost and schedule impact because the engineering capability is critical.

Sarah learned: Change control is not about saying "no." It is about making informed decisions when you understand the impact.

### 1.3.2.2 The Predictive Mindset

In predictive projects, the thinking goes like this:

**Plan thoroughly upfront because:**

- The cost of rework later is exponentially higher
- Many decisions (foundation, structure, regulatory approval) create path dependencies
- Stakeholders and financiers need confidence in a known scope, cost, and date
- Risks are identified and mitigated before they become problems

**Manage changes formally because:**

- Every change affects other parts of the plan
- You need to understand impact before agreeing to anything
- Stakeholders have made commitments (budgets, dates, resource allocations) based on the baseline
- Transparency and control protect both the project and the organization

**Measure performance against baselines because:**

- You set expectations upfront; now you track whether you are delivering on them
- Variance analysis (cost variance, schedule variance) tells you when to intervene
- Earned value lets you forecast: If you are 30% done with 50% of the budget, you are heading toward cost overrun

### 1.3.2.3 Predictive Planning and Control Mechanics

In predictive projects, you typically:

1. **Develop a detailed scope baseline** (for example, Work Breakdown Structure or WBS)
   - What will be delivered?
   - What is explicitly excluded?
   - What are the quality standards?

2. **Build a schedule** that sequences all major tasks, often using critical path analysis
   - What depends on what?
   - Which activities have slack, and which are on the critical path?
   - What is the earliest the project can finish?

3. **Develop a cost baseline** aligned with scope and schedule
   - How much does each phase cost?
   - What contingency is built in for risks?
   - What is the funding profile over time?

4. **Identify and plan for risks upfront**
   - What could go wrong?
   - For high-impact risks, what mitigation is built into the plan?

During execution:

- **Track actual work against the plan**: How much have you spent? How much work is done? Are you ahead or behind schedule?
- **Analyze variance**: If you are over budget or behind schedule, what caused it?
- **Forecast the outcome**: At the current rate, what will the final cost and date be?
- **Manage changes formally**:
  - Someone proposes a change (new requirement, scope adjustment, etc.)
  - You analyze the impact on cost, schedule, scope, quality, risk, and benefits
  - The change control board reviews and decides
  - If approved, you update the baseline and communicate the change to all stakeholders
  - If rejected, you explain why and discuss alternatives

### 1.3.2.4 When Predictive Works Well

Predictive approaches shine when:

- **Requirements are stable**: Once understood, they do not change significantly
- **The technical path is clear**: You know how to build what is needed
- **Risk is manageable through planning**: You can identify risks upfront and plan mitigations
- **Change is costly**: The cost of late changes is very high (safety, rework, schedule pressure)
- **Stakeholders need certainty**: Contracts, budgets, timelines are fixed and committed

### 1.3.2.5 When Predictive Struggles

Predictive approaches struggle when:

- **Requirements are unknown**: You do not know what the customer really needs until you show them something
- **The technical path is unclear**: You have never built this before; you will learn as you go
- **The environment is changing**: Market conditions, regulations, or technology evolve during the project
- **You need flexibility**: The value of the work comes from adapting to feedback

In these situations, predictive planning can create an illusion of certainty that does not match reality, leading to wasted effort on detailed plans that become obsolete.

### 1.3.2.6 On the Exam: Recognizing Predictive Scenarios

Exam questions signal a predictive environment through cues like:

- Fixed budget, schedule, or scope commitments
- Regulated industries or safety-critical work
- Detailed requirements defined upfront
- Fixed-price contracts or formal statements of work
- Formal change control boards mentioned in the scenario

When you see these cues, answers that follow the predictive playbook usually score well:

- Use formal change control for scope, schedule, or budget changes
- Refer to baselines and the business case when evaluating options
- Emphasize thorough planning and risk management
- Track performance against the plan and escalate variance
- Maintain detailed documentation for auditability and clarity

---

## 1.3.3 Agile and Adaptive Approaches in Practice

Agile/adaptive approaches are built around:

- Iterative and incremental delivery
- Frequent feedback from customers and stakeholders
- Flexible scope within a fixed time and cost boundary
- Learning and adaptation as the core strategy for managing uncertainty

The fundamental assumption: *You cannot predict the full scope upfront, so you will learn through delivery and adapt.*

Examples of agile environments:

- Digital products (mobile apps, SaaS platforms)
- Internal applications in fast-moving business domains
- Innovation efforts with high uncertainty
- Customer-facing work where market feedback shapes the direction

### 1.3.3.1 Story: Sarah's Expense Reporting Redesign (Sarah's Second Project)

A few weeks into her office renovation project, Sarah is assigned to lead the redesign of the company's internal expense reporting system. Her first instinct is to approach it like the office project:

*"I will gather all the requirements from every department, document them thoroughly, and then build the system."*

But when she talks to the CFO, she hears something different: *"Sarah, here is the problem: No one uses our current system well. People complain it is clunky, but when you ask them what they want instead, they are not entirely sure. We keep trying to add features, but it does not really solve the core problems. And honestly, we have no idea what expense technology will look like in two years."*

Sarah realizes: This is different from the office renovation.

**Sprint 1: Learning What People Actually Do**

Instead of spending three months gathering all requirements, Sarah decides to work in two-week sprints. The team is small: Sarah, a designer, two developers, and the CFO as the product owner.

In the first sprint, they:

- Interview people actually submitting expenses (not just asking what they want)
- Understand the current pain points
- Build a quick prototype of one feature: submitting a receipt photo instead of typing expense details
- Show the prototype to five users

The feedback is immediate and surprising: *"I love that I can just take a picture, but here is what is slowing me down even more: I have to categorize every single line item into cost centers, and I am not always sure which is correct."*

Sarah learns: What people say they want is often not their real problem.

**Sprint 2: Building Something Real**

Based on feedback, the team prioritizes the backlog:

- Automatic cost center suggestion (based on their past expenses)
- Receipt photo upload
- Simplified approval workflow for managers

They deliver these in Sprint 2. Again, they demo the work to actual users and the product owner.

Feedback: *"The cost center suggestions are helpful, but I still need to submit expenses on the go using my phone. This web interface is clunky on mobile."*

The backlog shifts. The team deprioritizes some features and adds: *Responsive mobile design for fast submission while traveling.*

**Sprints 3–8: Building and Learning**

Over six more sprints, the team:

- Adds each feature based on what was learned from user feedback
- Tests assumptions with real users
- Prioritizes ruthlessly: What provides the most value to the people doing the work?
- Occasionally discovers that a feature they planned is not actually useful
- Occasionally finds that a small feature unlocks a much bigger value

By Sprint 8, the team has delivered a system that:

- Took 16 weeks instead of an estimated 6-month waterfall approach
- Delivers genuine value to users (they are actually using it)
- Is mobile-friendly
- Has dramatically reduced submission errors
- Can be updated every two weeks with new features

If Sarah had used the predictive approach, she would have:

- Spent six weeks gathering requirements
- Delivered something that did not match how people actually work
- Spent months reworking it to fix problems that could have been caught earlier
- Angered users by forcing them to use a system that did not fit their reality

### 1.3.3.2 The Agile Mindset

In agile projects, the thinking goes like this:

**Plan at multiple time horizons because:**

- You cannot predict detailed requirements six months out, but you can commit to the next iteration
- You need a vision (where are we going?) but flexibility on the path to get there
- Learning happens through delivery, not through guessing

**Manage changes through prioritization because:**

- Everything is a change—you embrace change as inevitable
- The question is not "can we afford this change?" but "is this change more valuable than what we are currently doing?"
- The product owner arbitrates value trade-offs continuously

**Measure progress through working software/deliverables because:**

- The only real measure of progress is something that works
- You cannot fake a working feature or delivered value
- This creates transparency: If the team says "we are done," we have something to show

### 1.3.3.3 Agile Planning and Control Mechanics

In agile projects, you typically work in timeboxed iterations (sprints, typically 1–4 weeks) that follow a pattern:

1. **Product Backlog**: A prioritized list of features, improvements, and fixes
   - The product owner decides order based on value
   - Items can be reprioritized at any time
   - New items can be added as you learn

2. **Sprint Planning**: At the start of each sprint
   - The team reviews the top items in the backlog
   - The team estimates how much they can complete in the sprint (based on capacity)
   - They commit to a sprint goal

3. **Daily Stand-up**: Brief sync to keep everyone aligned
   - What did you finish yesterday?
   - What will you work on today?
   - What is blocking you?

4. **Sprint Work**: The team builds, tests, and validates
   - Work is integrated daily (not all at the end)
   - Quality is built in, not added later
   - Team adapts to learning and blockers

5. **Sprint Review**: Demo of completed work
   - Actual users see what was built
   - Feedback is gathered
   - This learning shapes the next sprint's priorities

6. **Sprint Retrospective**: Team reflection
   - What went well? What did not?
   - How can we improve our process?
   - Changes to how the team works are made immediately

During execution:

- **Track progress through working increments**: What is actually done?
- **Adapt the backlog continuously**: As you learn, reprioritize
- **Embrace scope flexibility**: If the team is overloaded, lower-priority items move to the next sprint or are canceled
- **Manage risk through early delivery**: By getting features to users early, you learn about risks before they become catastrophic
- **Maintain transparency**: Burn-down charts and backlogs are visible to everyone

### 1.3.3.4 When Agile Works Well

Agile approaches shine when:

- **Requirements are uncertain or evolving**: You need to learn as you go
- **The technical path is unclear**: You may discover better approaches as you build
- **Customer feedback drives value**: You need frequent validation that you are building the right thing
- **Time-to-value matters**: Delivering something usable every few weeks provides more value than waiting for a perfect product in six months
- **The environment is changing**: You need flexibility to adapt to market shifts, technology changes, or new priorities

### 1.3.3.5 When Agile Struggles

Agile approaches struggle when:

- **Scope must be controlled tightly**: If every feature is locked in a contract and changing scope is not allowed, agile's flexibility becomes a liability
- **The work cannot be incrementally delivered**: Some types of work (like building a bridge foundation) must be completed as a whole; you cannot deliver "half a foundation"
- **Regulatory or contractual requirements mandate a different approach**: If a contract specifies a detailed scope and fixed price, agile iterative delivery may violate the agreement
- **Integration points are delayed**: If the team is building components that do not integrate or provide value until the very end, agile loses its advantage

In these situations, agile can create chaos: teams delivering things that do not work together, or delivering work that cannot be integrated.

### 1.3.3.6 On the Exam: Recognizing Agile Scenarios

Exam questions signal an agile environment through cues like:

- Uncertain or evolving requirements
- Iterative delivery expected (sprints, releases mentioned)
- Product owner or customer involvement mentioned
- Feedback loops and learning emphasized
- Flexible scope but fixed time/cost mentioned
- High-uncertainty work or innovation projects

When you see these cues, answers that follow the agile playbook usually score well:

- Involve the product owner in prioritization decisions
- Use iterative delivery and feedback to validate assumptions
- Reprioritize the backlog when new information emerges
- Welcome and manage change through prioritization, not formal change control
- Measure progress through working deliverables
- Seek user/customer feedback early and often

---

## 1.3.4 Hybrid Approaches: Combining Predictive and Agile

Hybrid approaches recognize that many projects have:

- Some elements that are stable and can be planned predictively
- Other elements that are uncertain and benefit from agile delivery
- The need to be strategic about where you use each approach

The fundamental assumption: *Different parts of the work have different characteristics; treat them accordingly.*

A hybrid approach might:

- Use predictive practices for:
  - Overall program structure and governance
  - Regulatory milestones and compliance
  - Contractual commitments and budgets
  - Infrastructure and foundational work

- Use agile practices for:
  - Developing features within a platform
  - Experimenting with customer-facing capabilities
  - Iterating on user experience
  - Solving uncertain technical problems

### 1.3.4.1 Story: Sarah's Transformation Program (Sarah's Third Project)

At the end of her first month, Sarah's boss has an unexpected conversation with her: *"Sarah, you have handled the office renovation and the expense system well. But we have a bigger challenge. We are launching a new way of working across the company. We are moving people together into the new office at a specific date. But we also need to fundamentally change how teams work—from individual contributors to cross-functional collaboration. We are not sure what the new way of working will look like exactly, but we know the deadline is firm."*

Sarah realizes: Neither predictive nor agile alone will work.

The challenge has:

- **Predictive elements**:
  - A firm move-in date (connected to the office renovation)
  - A fixed budget for the transformation
  - A regulatory requirement to complete certain training by a specific date
  - A contractual commitment to leadership about when the transformation would be done

- **Agile elements**:
  - No one is entirely sure what "new way of working" means for different departments
  - Different teams will need different changes (sales, engineering, finance have very different work)
  - The company will learn as they go what practices work best for their culture
  - Flexibility to adapt based on what teams discover

Sarah designs a hybrid program:

**Program-Level (Predictive)**

- A master roadmap with three phases, each aligned to the office move milestones:
  - **Phase 1 (Months 1–4)**: Foundation and planning
  - **Phase 2 (Months 5–12)**: Pilot and refinement
  - **Phase 3 (Months 13–18)**: Full rollout and stabilization

- A program budget: $2 million, allocated to training, coaching, tools, and design work

- Program governance: Monthly steering committee reviews tracking:
  - Are we on track for the Phase 2 pilot?
  - Are we on budget?
  - What risks could delay the Phase 3 rollout?

- Compliance checkpoints: Training completion tracked against the regulatory deadline

**Team-Level (Agile)**

Within each phase, teams work in agile sprints to design and test the new way of working:

- **Phase 1, Sprint 1**: Research what makes teams effective
  - Interview high-performing teams
  - Research best practices in agile/collaborative ways of working
  - Identify what might work for this company

- **Phase 1, Sprint 2–3**: Design a target operating model
  - What roles will teams have?
  - What rituals and rhythms will support collaboration?
  - What tools will they use?
  - Get feedback from teams

- **Phase 2, Sprint 1–4**: Pilot with three volunteer teams
  - Three teams try the new way of working for four sprints
  - Weekly sprint reviews with their teams
  - Retrospectives focused on what is working and what is not
  - Learning flows back to the design team
  - Iterate based on feedback

- **Phase 2, Sprint 5–8**: Refine and scale
  - Design is updated based on pilot learnings
  - Expand to more teams
  - Continue gathering feedback

- **Phase 3, Sprints 1–12**: Rollout aligned to office move
  - Train and onboard teams as they move into the new office
  - Support teams in the transition with coaching
  - Handle unexpected challenges in real-time
  - Maintain the program schedule to stay aligned with the move

**Why Hybrid Works Here**

Sarah chose this approach because:

- **Program level needs predictability**: The office move is a hard constraint. She needs leadership to have confidence that the transformation will support the move-in date. That requires a master roadmap and governance.

- **Team level needs flexibility**: No one knows exactly what practices will work for this company. By running pilots and sprints, Sarah's team learns what is actually effective before rolling it out company-wide.

- **Risks are managed at both levels**: If a team pilot reveals that the new way of working is not working, the program can adapt before the full rollout. But the program schedule keeps everything on track for the move-in date.

- **Stakeholders see progress both ways**: The program steering committee sees a roadmap and milestones (predictive, reassuring to executives). Teams see working practices being tested and refined (agile, reassuring to people concerned about change).

**When Sarah Encounters a Hybrid Challenge**

Three months into the program, the pilot teams report: *"The new collaborative practices are working well, but we need a different tool than what was planned. The tool in the program budget will not support what we are trying to do."*

Sarah must make a decision that balances both approaches:

- **Predictive constraint**: The program budget is $2M. Adding a new tool costs $150K and uses budget planned for other things.

- **Agile reality**: The pilot teams have learned something critical. Ignoring it risks the entire transformation.

Sarah takes this to the program steering committee. She shows:

- The pilot feedback (evidence-based)
- The impact on the program budget and timeline
- Options: Reduce scope elsewhere, ask for more budget, delay certain features

The steering committee decides: Approve the tool, and defer some training that can happen post-move.

Sarah learned: In hybrid programs, you use predictive governance to make high-level trade-offs, but you respect agile learning from the ground level.

### 1.3.4.2 When Hybrid Works Well

Hybrid approaches shine when:

- **Part of the work is stable; part is uncertain**: Different components have different characteristics
- **You have fixed endpoints**: A deadline or budget limit is immovable, but the path to get there can flex
- **Learning matters**: You need to adapt based on pilot results, but you also need overall direction
- **Stakeholders need different communication**: Executives want a roadmap; teams want freedom to innovate
- **Integration is critical**: Some work must be coordinated predictively; other work can proceed independently and adapt

### 1.3.4.3 When Hybrid Struggles

Hybrid approaches struggle when:

- **You use it as an excuse for lack of clarity**: Saying "it is hybrid" when you really mean "we have no idea what we are doing" creates confusion
- **You try to apply both approaches equally everywhere**: Hybrid is not 50% predictive + 50% agile everywhere; it is *selective* use of each where it fits
- **Governance is ambiguous**: If it is unclear when decisions are made predictively (top-down by steering committee) and when they are made agilely (by teams), you get conflicts and delays
- **Integration points are not managed**: If the agile teams' output does not integrate into the predictive program structure, you end up with disconnected pieces

### 1.3.4.4 On the Exam: Recognizing Hybrid Scenarios

Exam questions signal a hybrid environment through cues like:

- A mix of stable and uncertain work
- Fixed deadline or budget alongside evolving requirements
- Multiple teams or components with different characteristics
- Pilot, test, or learn phases mentioned alongside final rollout
- Program-level governance alongside team-level flexibility
- Regulatory or contractual constraints balanced against innovation

When you see these cues, answers that follow the hybrid playbook usually score well:

- Use predictive planning for the stable, high-constraint elements
- Use agile practices for the uncertain, learning-oriented elements
- Design clear governance that specifies where each approach applies
- Balance flexibility with control—agile teams operate within predictive guardrails
- Learn from pilots and adapt the program plan accordingly
- Communicate progress in ways that make sense to both executives and teams

---

## 1.3.5 Tailoring: Choosing and Adapting Your Way of Working

Tailoring means:

- Selecting and adjusting processes, artifacts, and tools
- Based on the size, complexity, risk, and context of your initiative
- Making deliberate choices about what to emphasize and what to de-emphasize

It is **not**:

- Ignoring practices you dislike because you find them annoying
- Slapping the label "hybrid" on a chaotic process with no clear governance
- Abandoning structure and discipline because "we are being agile"
- Using "tailoring" as an excuse to skip critical practices like risk management or stakeholder engagement

### 1.3.5.1 Sarah's Tailoring Framework

After managing three very different projects, Sarah realizes she needs a systematic way to think about tailoring. Here is the framework she develops:

**First, understand the context:**

1. **What is the level of requirement uncertainty?**
   - Can stakeholders define what they need clearly upfront? (Office: Yes. Expense system: No. Transformation: Partial.)
   - Will the requirements change significantly during the work? (Office: Low change. Expense: High change. Transformation: Moderate change in parts.)

2. **Can the work be incrementally delivered?**
   - Can you deliver useful value in pieces, or must it all come together at once? (Office: Must be together. Expense: Can be phased. Transformation: Can be phased with pilots.)
   - Can stakeholders provide early feedback on incomplete work? (Office: Limited. Expense: High. Transformation: High.)

3. **What is the risk and impact if things go wrong?**
   - What are the consequences of failure? (Office: High financial, schedule impact. Expense: Medium. Transformation: Medium to high, if people do not adopt new ways.)
   - What is the organization's tolerance for iteration and learning? (Office: None. Expense: High. Transformation: Medium if pilots show value.)

4. **Are there external constraints or contractual commitments?**
   - Fixed deadline? (Office: Firm. Expense: Flexible. Transformation: Firm move-in, flexible in detail.)
   - Fixed budget? (Office: Fixed. Expense: Flexible. Transformation: Fixed program, flexible allocation.)
   - Fixed scope/requirements in a contract? (Office: Yes. Expense: No. Transformation: Partial—the move date is fixed, but the practices are not.)
   - Regulatory or compliance requirements? (Office: Yes. Expense: No. Transformation: Yes for training.)

5. **What is the team's capability and culture?**
   - Are teams experienced with the approach you are considering? (Sarah's teams: Experienced with predictive. Learning agile. Some resistance to change.)
   - How much structure does the organization need to feel confident? (Sarah's company: Executives want roadmaps; teams want autonomy.)

### 1.3.5.2 Tailoring Examples from Sarah's Experience

**Example 1: The Office Renovation (Predominantly Predictive)**

| Factor               | Finding                                                  | Implication                         |
| -------------------- | -------------------------------------------------------- | ----------------------------------- |
| Uncertainty          | Requirements stable and well-understood                  | Plan detailed upfront               |
| Incremental delivery | Cannot deliver in pieces                                 | All-or-nothing delivery at the end  |
| Risk and impact      | High financial and schedule impact                       | Careful planning and change control |
| Constraints          | Fixed deadline, fixed budget, fixed requirements in bids | Formal baselines and tracking       |
| Team capability      | Traditional project management culture                   | Formal governance and documentation |

**Tailored approach:**
- Detailed upfront planning: WBS, schedule, budget, risk register
- Formal change control with change control board
- Monthly status reviews against baselines
- Earned value analysis
- Extensive documentation and formal sign-offs
- Heavy emphasis on specification and compliance

**Why this works:** The office project has everything that calls for predictive: stable requirements, high consequences, fixed constraints, and a culture that expects structure. Trying to be agile would create chaos and risk missing the move-in date.

---

**Example 2: The Expense Reporting System (Predominantly Agile)**

| Factor               | Finding                                                                     | Implication                               |
| -------------------- | --------------------------------------------------------------------------- | ----------------------------------------- |
| Uncertainty          | Requirements unknown; people do not know what they want                     | Learn by building and gathering feedback  |
| Incremental delivery | Can deliver features incrementally; users can use partially finished system | Iterate and release every few weeks       |
| Risk and impact      | Medium impact; organization tolerates learning and adaptation               | Can afford to experiment                  |
| Constraints          | Flexible timeline and budget                                                | No hard deadline                          |
| Team capability      | Team new to agile; willing to learn                                         | Structure with coaching and clear rituals |

**Tailored approach:**
- Light upfront design; focus on understanding user pain points, not detailing all features
- Timeboxed sprints (2 weeks)
- Frequent releases: every 2–4 weeks users see new features
- Product owner prioritization based on user feedback and value
- Daily stand-ups to keep team aligned
- Minimal formal documentation; focus on working software
- Retrospectives to improve how the team works

**Why this works:** No one knows what the right solution is. Spending months on detailed requirements would guarantee you build the wrong thing. By iterating quickly and showing real work to users, the team learns and delivers genuine value.

---

**Example 3: The Transformation Program (Hybrid with Clear Layers)**

| Factor               | Finding                                                            | Implication                                               |
| -------------------- | ------------------------------------------------------------------ | --------------------------------------------------------- |
| Uncertainty          | Mix: move date is certain; new ways of working are uncertain       | Predictive program structure; agile team practices        |
| Incremental delivery | Program must be integrated; teams can pilot and iterate            | Predictive rollout schedule; agile discovery within gates |
| Risk and impact      | High impact if adoption fails; tolerance for learning in pilots    | Pilot first, then scale predictively                      |
| Constraints          | Fixed move-in date; fixed training deadline; flexible on practices | Predictive deadlines; agile path to get there             |
| Team capability      | Teams new to collaborative practices; need structure               | Clear governance; safe-to-fail pilots; coaching           |

**Tailored approach:**
- **Program level**: Three-phase roadmap (Foundation, Pilot, Rollout) aligned to move dates
- **Program governance**: Monthly steering committee reviews; go/no-go decisions at phase gates
- **Team level**: Agile sprints within each phase; pilots before full rollout
- **Feedback loops**: Pilot learnings flow back to program planning
- **Communication**: Roadmap for executives; backlog and sprints for teams
- **Change process**: Steering committee handles scope trade-offs (hybrid change); teams handle backlog prioritization (agile)

**Why this works:** The firm move-in date requires a predictive program schedule. But the uncertainty about what new practices will work requires agile discovery. By piloting first (agile), then scaling (predictive), Sarah gets the benefits of both approaches.

### 1.3.5.3 Tailoring Questions to Ask

When you are designing your approach, ask yourself:

1. **Uncertainty**: Can we predict what we will build, or must we learn by doing?
   - High prediction → More predictive practices
   - High uncertainty → More agile practices

2. **Incrementality**: Can we deliver value in phases, or is integration delayed?
   - Can deliver in phases → Agile-friendly
   - All-at-once delivery → Predictive-friendly

3. **Risk tolerance**: If we get it wrong, what are the consequences, and how much iteration can we afford?
   - High consequence, low tolerance → More predictive controls
   - Medium consequence, medium tolerance → Hybrid or agile with oversight
   - Low consequence, high tolerance → More flexibility and agile

4. **Constraints**: What is fixed (deadline, budget, scope)?
   - Fixed scope and deliverables → Predictive
   - Fixed time/budget, flexible scope → Agile
   - Some fixed, some flexible → Hybrid

5. **Stakeholders**: What communication and governance do stakeholders expect?
   - Expect detailed plans and formal governance → Predictive
   - Expect regular working deliverables and feedback loops → Agile
   - Expect both → Hybrid

6. **Team capability**: Is the team experienced with the approach?
   - Experienced with approach → Can use it effectively
   - New to approach → Need training, coaching, or scaffolding

### 1.3.5.4 Common Tailoring Mistakes

**Mistake 1: "We'll use agile because it is trendy"**
- Reality: Agile is not inherently better; it is better for specific contexts
- Fix: Choose agile because you have uncertain requirements or need rapid feedback, not just because it sounds cool

**Mistake 2: "We'll be predictive because we always have been"**
- Reality: Organizational inertia is not a valid tailoring reason
- Fix: Ask whether the context has changed. If you now face more uncertainty or need faster feedback, adapt your approach

**Mistake 3: "We'll call it hybrid so we can do whatever we want"**
- Reality: Hybrid requires *more* clarity about where each approach applies, not less
- Fix: Be explicit: "We use predictive planning at the program level and agile delivery at the team level, with this governance in between"

**Mistake 4: "Tailoring means dropping the practices we do not like"**
- Reality: Tailoring is about emphasizing practices that fit the context, not abandoning critical disciplines
- Fix: You might do lighter documentation in agile, but you still manage risk, stakeholders, and quality; you just do it differently

**Mistake 5: "We'll adapt our approach as we go with no upfront choice"**
- Reality: If you start predictive and switch to agile mid-project (or vice versa), you often get the worst of both
- Fix: Make a deliberate choice early, with permission to adapt if the context fundamentally changes

### 1.3.5.5 On the Exam: Tailoring Scenarios

Exam questions test tailoring by presenting a scenario and asking: *"Given this context, what is the most appropriate way to work?"*

You will see scenarios like:

- A project with fixed budget and scope, but the technical approach is uncertain
- A program with a firm deadline but uncertain scope
- A small team doing something no one has done before
- A large organization with strict governance requirements building something novel

**Good tailoring answers:**
- Identify what is certain and what is uncertain
- Propose an approach that matches the context
- Explain *why* the approach fits (not just "we should do hybrid")
- Recognize trade-offs: Every choice emphasizes something and de-emphasizes something else

---

## 1.3.6 Governance, Cadence, and Communication Across Approaches

Different ways of working imply different rhythms, decision-making structures, and communication patterns. Understanding these differences is critical on the exam and in real projects.

### 1.3.6.1 Governance: How Decisions Get Made

**In Predictive Contexts (Like Sarah's Office Renovation):**

- **Who decides**: Formal governance bodies (Change Control Board, Project Steering Committee)
- **When decisions are made**: At planned stage gates or when formal change requests arrive
- **How decisions are made**: Based on impact analysis against the baseline and business case
- **What decisions are made**: Approve/reject scope, schedule, budget, and risk changes
- **Escalation**: If the CCB cannot decide, it goes to the sponsor or portfolio governance

Example from Sarah's project:
- *"VP of Engineering wants to add three server rooms. Sarah presents the impact: +$250K, +4 weeks. CCB decides: approve, adjust budget and timeline."*
- The CCB has authority to make trade-offs because the baseline is clear and understood.

**In Agile Contexts (Like Sarah's Expense System):**

- **Who decides**: Product owner (with input from the team and stakeholders)
- **When decisions are made**: Continuously, during backlog refinement and sprint planning
- **How decisions are made**: Based on value, effort, and priority
- **What decisions are made**: Reprioritize work, add/remove features, adjust scope
- **Escalation**: If a feature has strategic importance, the product owner escalates to leadership for value confirmation

Example from Sarah's project:
- *"Users want mobile responsiveness. PM asks: Does this provide more value than the features we planned? Product owner decides: Yes, add it to the backlog and prioritize it above X."*
- The product owner has authority because flexibility on scope is expected.

**In Hybrid Contexts (Like Sarah's Transformation):**

- **Who decides**: Steering committee for program-level decisions; product owner for team-level decisions
- **When decisions are made**: Program reviews monthly; backlog decisions continuously
- **How decisions are made**: Program decisions by impact on milestones and budget; team decisions by value and iteration capacity
- **What decisions are made**: Program decisions affect overall roadmap and go/no-go gates; team decisions affect which features are tackled next
- **Escalation**: If a team's need conflicts with program constraints, it escalates to the steering committee

Example from Sarah's project:
- *"Pilot teams discover they need a different tool. Sarah escalates: Does this change the budget or timeline? Steering committee says: Approve, defer some other training."*
- The escalation is needed because the program-level constraints (budget, timeline) are involved.

### 1.3.6.2 Cadence: The Rhythm of Work

**Predictive Cadence:**

- Major milestones every 1–3 months (or longer for multi-year projects)
- Formal status reviews at each milestone
- Change control reviews when requests arrive (ad hoc, but can happen any time)
- Progress measured against baselines monthly

*Sarah's office project cadence:*
- Monthly status meetings with the steering committee
- Quarterly milestone reviews (end of each phase)
- Change control board meets when changes are submitted

**Agile Cadence:**

- Iterations (sprints) every 1–4 weeks, typically 2 weeks
- Daily stand-ups to sync the team
- Sprint planning at the start of each iteration
- Sprint review (demo) at the end of each iteration
- Sprint retrospective to improve the process

*Sarah's expense system cadence:*
- 2-week sprints
- Daily 15-minute stand-ups
- Every sprint: planning meeting, demo, and retrospective
- Users see new features every 2 weeks

**Hybrid Cadence:**

- Program reviews every 1–3 months aligned to major phases
- Team sprints every 1–4 weeks
- At phase gates: go/no-go decision based on team progress against program plan

*Sarah's transformation cadence:*
- Monthly steering committee reviews
- Phase gates at Months 4, 12, and 18
- Team sprints within each phase (2 weeks per sprint)
- Learning from pilots fed into program planning

### 1.3.6.3 Communication: Speaking Different Languages

One of the biggest challenges in hybrid and complex projects is that different audiences need different information.

**What executives care about:**
- Are we on track to deliver by the deadline?
- Will the budget hold?
- What are the top risks?
- Is the business value clear?

**What teams care about:**
- What am I working on this sprint/week?
- What is blocking me?
- How is my work contributing to the goal?
- Do I have the support and clarity I need?

**What customers/users care about:**
- When will I see new capabilities?
- Is this thing actually going to solve my problem?
- Can I try it and give feedback?

Sarah's communication strategy for each project:

**For the office renovation (Predictive):**
- **To the steering committee**: Monthly status reports showing variance from baseline
  - Schedule variance: Are we ahead or behind the plan?
  - Cost variance: Are we over or under budget?
  - Risk register: What could derail us, and how are we mitigating?
- **To the contractor teams**: Detailed plans, blueprints, specifications
  - What exactly needs to be built?
  - What are the acceptance criteria?
  - What dependencies are there?
- **To the company**: Town halls at major milestones
  - When is the move happening?
  - What should I prepare?
  - Who should I contact with questions?

**For the expense system (Agile):**
- **To the CFO (product owner)**: Weekly check-ins on priorities and feedback
  - What did we just show users?
  - What did users say?
  - What should we prioritize next?
- **To the team**: Daily stand-ups and sprint rituals
  - What is the sprint goal?
  - What are we working on today?
  - What is in the way?
- **To users**: Every 2 weeks, a demo of new features
  - Here is what we built; try it
  - What feedback do you have?
  - What would make this more useful?

**For the transformation (Hybrid):**
- **To the steering committee**: Monthly reviews with both roadmap and learning
  - Here is the program master schedule
  - Here is what the pilot teams are learning
  - Here is how the learning affects the plan
  - Do we proceed to the next phase?
- **To the design teams**: Sprint ceremonies and pilot retrospectives
  - What is the sprint goal?
  - What are pilot teams telling us?
  - What needs to change based on learning?
- **To the broader organization**: Town halls explaining the "why" and progress
  - Why are we changing how we work?
  - Here is what early adopters are learning
  - Here is how this will roll out

### 1.3.6.4 When Governance and Communication Misalign

Sarah learns a hard lesson midway through the transformation: Poor communication about governance creates confusion.

The steering committee approves a budget reallocation based on pilot learning. But Sarah forgets to clearly communicate to the pilot teams that this changes what is expected of them. The result:

- Teams think they have more flexibility than they do
- Steering committee thinks changes will be in place by a certain date
- When the date arrives, expectations are not met

Sarah learns: **Governance and communication must be aligned.** People need to know:
- Who makes what decisions
- When decisions are made
- How those decisions affect the work
- What is expected of them in light of those decisions

On the exam, questions test this by presenting scenarios where communication or governance is unclear, and asking you to identify the problem or recommend a fix.

### 1.3.6.5 On the Exam: Governance and Communication Red Flags

The exam often includes scenarios where governance or communication is broken. Watch for red flags like:

- *"The sponsor approved the change, but no one told the team"* → Communication problem
- *"We do not know who decides if we should pivot"* → Governance problem
- *"The team is operating independently with no alignment to the program"* → Governance and communication problem
- *"Stakeholders think we are on track; the team knows we will miss the deadline"* → Communication breakdown

Good answers often include:
- Establishing clear decision-making authority and process
- Communicating decisions and their implications to affected parties
- Creating feedback loops so that learning flows back to decision-makers
- Matching the governance and communication approach to the way of working

---

## 1.3.7 Common Exam Traps About Ways of Working

Several recurring traps appear in PMP questions related to ways of working. Sarah encounters some of these in her first month and learns what not to do.

### 1.3.7.1 Trap 1: "Method Evangelism" (Choosing Based on Preference, Not Context)

**The trap:**
- Options insist that one method is always better
- Examples: *"Always use agile because it is modern," "Never use agile because it is chaotic," "Always create a detailed plan first"*

**Why it is wrong:**
- The right way of working depends on context
- A "best practice" in one situation is a disaster in another

**Real example from Sarah:**
- Sarah's boss asks her to apply the same approach to all three projects
- Sarah initially thinks: *"I learned traditional project management; I'll use that for everything"*
- Almost derails the expense system project (which needed agility)
- Almost creates unnecessary overhead in the office project if she tried to apply agile practices

**On the exam:**
- Watch for options that use absolute language: "always," "never," "the best way is..."
- Better answers say: "In this context, this approach fits because..."

**Red flag answers:**
- *"Use agile; it is more efficient"* → Ignore context about fixed scope or safety-critical work
- *"Always use predictive for regulated industries"* → Might miss that even regulated industries have parts that need agile exploration
- *"Use whatever method you prefer"* → No consideration of context at all

### 1.3.7.2 Trap 2: Ignoring Context (Choosing Without Understanding the Scenario)

**The trap:**
- Options select an approach without considering industry, risk level, uncertainty, or regulatory requirements
- They sound good in general but do not fit the specific scenario

**Why it is wrong:**
- Context determines which approach will actually work
- Ignoring context leads to projects that fail or create unnecessary overhead

**Real example from Sarah:**
- If Sarah had said, *"Let's be agile for the office renovation because it is trendy,"* the project would have failed
- The building needs to be ready by a specific date; the design needs to be locked in early; changes are enormously costly
- Agility would have created chaos: contractors without clear specifications, scope creeping, impossible deadlines

**On the exam:**
- Read the scenario carefully: What industry? What constraints? What is the risk?
- Ask yourself: Given these conditions, which approach makes sense?
- Watch for options that ignore specific constraints mentioned in the scenario

**Red flag answers:**
- Ignores a fixed deadline or regulatory requirement mentioned in the scenario
- Does not account for the level of uncertainty or stability described
- Does not consider the team's experience level
- Does not address integration challenges (parts must work together)

### 1.3.7.3 Trap 3: Misusing Agile or Predictive Language (Calling It One Thing While Doing Another)

**The trap:**
- A scenario says "we are agile" but uses predictive practices (or vice versa)
- Or the response recommends a practice that contradicts the stated approach

**Why it is wrong:**
- Misalignment between stated and actual practices creates confusion and inefficiency
- You cannot claim to be agile while ignoring user feedback and customer involvement
- You cannot be purely predictive if you lack enough information to plan accurately upfront

**Real example from Sarah:**
- A team says: *"We are agile"* but then:
  - Never shows working software to users
  - Freezes the plan and resists any changes
  - Focuses on following the schedule rather than delivering value
- This is actually predictive behavior mislabeled as agile

**On the exam:**
- If the scenario says "agile," look for options that include:
  - Product owner involvement
  - Iterative delivery and feedback
  - Backlog prioritization
  - Learning and adaptation
- If the scenario says "predictive," look for options that include:
  - Detailed upfront planning
  - Formal change control
  - Baseline tracking
  - Specification and documentation

**Red flag answers:**
- *"We will be agile by doing detailed upfront planning"* → Contradictory
- *"We will use predictive with a flexible scope"* → Contradictory
- *"We will use agile but never show work to users until it is complete"* → Contradictory
- *"We will do both agile and predictive the same way"* → Misses the point of hybrid (selective use)

### 1.3.7.4 Trap 4: "Tailoring" as an Excuse to Skip Critical Practices

**The trap:**
- "Tailoring" is used to justify skipping critical practices like:
  - Risk management
  - Stakeholder engagement
  - Quality checks
  - Communication
  - Change control

**Why it is wrong:**
- Tailoring means *emphasizing what fits the context*, not abandoning discipline
- Some practices are critical regardless of approach:
  - You always need to identify and manage risks
  - You always need to engage stakeholders
  - You always need to ensure quality
  - You always need to communicate clearly

**Real example from Sarah:**
- A team says: *"We are agile, so we do not need to manage risks"*
- Reality: Agile teams still identify risks; they just manage them through rapid feedback and adaptation rather than upfront planning
- Or a team says: *"We are predictive, so we do not need stakeholder feedback"*
- Reality: You always need stakeholder engagement; the timing and formality differ by approach

**On the exam:**
- Watch for answers that claim to "tailor away" fundamental practices
- Better answers show how a practice is adapted, not eliminated

**Red flag answers:**
- *"We do not need risk management because we are agile"* → Wrong; agile still manages risk
- *"We will skip stakeholder engagement to speed up planning"* → Wrong; stakeholder engagement is always needed
- *"We will not document anything because we are doing a hybrid project"* → Wrong; documentation needs may be lighter, but some is still needed
- *"We are tailoring, so we can ignore the regulatory requirement"* → Wrong; constraints are constraints

### 1.3.7.5 Trap 5: Not Recognizing Hybrid Complexity (Treating Hybrid as One-Size-Fits-All)

**The trap:**
- Thinking that hybrid means: *"Do 50% agile and 50% predictive everywhere"*
- Not being clear about where each approach applies
- Creating ambiguous governance and communication

**Why it is wrong:**
- Hybrid is not a middle ground; it is selective use of practices
- Without clarity on what is predictive and what is agile, you get confusion
- Example: If it is unclear whether the budget is flexible or fixed, teams and sponsors will disagree on whether a change can be approved

**Real example from Sarah:**
- The transformation program has:
  - Predictive: program roadmap, phase gates, training deadline
  - Agile: team sprints, pilot learning, backlog prioritization
- But Sarah must be crystal clear:
  - The phase gates and move-in date are firm (predictive)
  - The team's approach to discovering new practices is iterative (agile)
  - Decisions about features come from backlog (agile); decisions about phases come from steering committee (predictive)
- If this is not clear, chaos results

**On the exam:**
- When you see a hybrid scenario, ask: What is stable? What is uncertain? What is the governance for each?
- Better answers are specific: *"Use predictive for X because... Use agile for Y because..."*
- Watch out for answers that are fuzzy about governance

**Red flag answers:**
- *"We will be hybrid"* → Vague; what does this actually mean?
- *"Everyone will have some agility and some predictability"* → Unclear; where does each apply?
- *"The team can decide whether to be agile or predictive as they go"* → Dangerous; lack of clarity creates conflict
- *"We will do agile for some sprints and predictive for others"* → Unclear governance

### 1.3.7.6 Trap 6: Confusing "Flexibility" with "No Structure"

**The trap:**
- Thinking that because a project is agile or flexible, there is no need for:
  - Clear goals
  - Acceptance criteria
  - Definition of done
  - Architecture or design thinking

**Why it is wrong:**
- Flexibility in scope is not the same as flexibility in discipline
- Without clear definition of success, you cannot measure progress
- Without some architecture thinking, you build yourself into a corner

**Real example from Sarah:**
- The expense system is agile, but Sarah still:
  - Defines a clear vision: *"Make it easier for people to submit and manage expenses"*
  - Has the team define "done": *"Feature is coded, tested, documented, and deployed"*
  - Does some architecture thinking: *"Mobile-first responsive design so it works on phones"*
- These are not rigid; they evolve. But they provide structure.

**On the exam:**
- Better answers show that agile/flexible approaches still have discipline, just applied differently
- Watch for options that seem to suggest "no planning" or "no clarity"

**Red flag answers:**
- *"We will just start building and see what happens"* → No vision or direction
- *"We will not define acceptance criteria; the customer will decide when it is done"* → Unclear success
- *"We will change direction based on every whim"* → No prioritization or value focus

### 1.3.7.7 Strategy: How to Avoid These Traps on the Exam

When you encounter a ways-of-working question:

1. **Read the context first** (before looking at options)
   - Industry and risk level?
   - Fixed constraints (deadline, budget, scope)?
   - Level of uncertainty?
   - Team experience?
   - Regulatory or cultural requirements?

2. **Identify the likely approach**
   - High uncertainty + flexible scope → Agile-friendly
   - Stable requirements + fixed constraints → Predictive
   - Mix of both → Hybrid

3. **Evaluate options against context**
   - Does this option fit the context described in the scenario?
   - Would this option actually work given the constraints?
   - Does it miss any critical factors?

4. **Watch for red flags in options**
   - Absolute language ("always," "never")
   - Ignoring constraints mentioned in the scenario
   - Misalignment between stated and implied practices
   - Vague "tailor" language with no specifics
   - Skipping fundamental practices

5. **Prefer answers that**
   - Reference specific context clues from the scenario
   - Explain *why* an approach fits (not just that it does)
   - Balance structure with flexibility appropriately
   - Address governance and communication clearly
   - Recognize trade-offs

---

## 1.3.8 Sarah's Learning: One Month In

By the end of her first month, Sarah has experienced the differences between predictive, agile, and hybrid approaches firsthand. Here is what she has learned:

**The office renovation taught her:**
- When requirements are stable and constraints are firm, detailed upfront planning is not bureaucratic overhead—it is essential
- Change control is not about saying "no"; it is about making informed decisions
- Formal governance and communication protect both the project and the organization
- Some projects must succeed on the first try; there is no room for iteration

**The expense system taught her:**
- When requirements are unknown, trying to plan everything upfront wastes time
- Learning happens through delivery, not through planning meetings
- Users cannot tell you what they want until they see something; you must learn through feedback
- Flexibility on scope is a strength, not a failure to plan
- Early delivery of working software is more valuable than perfect planning

**The transformation taught her:**
- Most real work is not purely predictive or purely agile; it is mixed
- Different parts of the same initiative can use different approaches
- Governance and communication must be clear or chaos results
- Pilots allow you to learn before you scale
- Strategic constraints (like a move date) require predictive roadmaps; discovery work requires agile freedom

**Sarah's key realization:**
- The "right" way of working is not an ideology; it is a response to context
- Great project managers do not have a favorite methodology; they have a diagnostic toolkit
- Tailoring is not about dropping the practices you do not like; it is about emphasizing what fits the context
- Every choice has trade-offs; better project managers understand the trade-offs and make them consciously

**For the exam:**
- When you see a ways-of-working question, think like Sarah
- Start by understanding the context: What is stable? What is uncertain? What are the constraints?
- Then ask: Given this context, what approach actually makes sense?
- Explain your reasoning with reference to the specifics of the scenario
- Recognize that there is usually no "right" approach in the abstract—only the right approach for this situation